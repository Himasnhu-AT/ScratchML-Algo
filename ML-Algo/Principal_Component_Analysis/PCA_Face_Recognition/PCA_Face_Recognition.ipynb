{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# README\n",
        "\n",
        "Import archive.zip, test1.jpg, test2.jpg, test3.jpg, test4.jpg, test5.jpg, test6.jpg, test7.jpg, test8.jpg, test9.jpg, and test10.jpg from the assignment folder before the colab file. \n",
        "\n",
        "I had imported it in sample_data. You can follow the same, or else can change the datapath in the corresponding code sections."
      ],
      "metadata": {
        "id": "IQ6_KflU86Q5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5_qr8Gwnvek"
      },
      "outputs": [],
      "source": [
        "# Import all the necessities for the project.\n",
        "import os, glob\n",
        "from sklearn import preprocessing\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "The archive.zip contains the AT&T database of faces. It contains 400 images ( 10 images each of 40 persons). I have used the 9 image each of every person for training and 1 image each is left for the test set."
      ],
      "metadata": {
        "id": "mGi1PJg555Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = '/content/sample_data/archive.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall('/content/sample_data/faces')\n",
        "  print('Done')\n",
        "\n",
        "path = '/content/sample_data/faces' #path to the dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0K0lEp1qWVs",
        "outputId": "646fa50c-e683-4883-a942-86f3fb8ef579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlE20eqOnveo"
      },
      "outputs": [],
      "source": [
        "# This function plots the images\n",
        "def plot_images(images, titles, h, w, row, col):\n",
        "    plt.figure(figsize=(2.5*col,2.5*row))\n",
        "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.20)\n",
        "    for i in range(row * col):\n",
        "        plt.subplot(row, col, i + 1)\n",
        "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
        "        plt.title(titles[i])\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVBoqYUYnvep",
        "outputId": "3d4c8dc9-7eaa-4a1b-e135-eabba8e268c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360\n"
          ]
        }
      ],
      "source": [
        "# Counts the total number of images\n",
        "total_images = 0\n",
        "shape = None\n",
        "for images in glob.glob(path + '/**', recursive=True):         # The glob module is used to retrieve files/pathnames matching a specified pattern\n",
        "    if images[-3:] == 'pgm' or images[-3:] == 'jpg':\n",
        "        total_images += 1\n",
        "\n",
        "# 40 images, i.e. 1 for each person is separated for testing purposes\n",
        "total_images = total_images - 40\n",
        "print(total_images)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code section below plots the images in the training set."
      ],
      "metadata": {
        "id": "Fk2Fl-WC6VBK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpFos0BRnveq"
      },
      "outputs": [],
      "source": [
        "# Size of the images\n",
        "shape = (112,92) \n",
        "\n",
        "# Initialize the array which contains all the images\n",
        "train_images = np.zeros((total_images, shape[0], shape[1]) ,dtype='float64')\n",
        "test_images = np.zeros((40, shape[0], shape[1]) ,dtype='float64')\n",
        "test_images_dict = dict()\n",
        "id_train = list()\n",
        "id_test = list()\n",
        "i = 0\n",
        "j = 0\n",
        "# Traverse through the folder which contains all the faces\n",
        "for folder in glob.glob(path + '/*'):\n",
        "    # Iterates through all the 10 images in folder and appends in id_train list()\n",
        "    for q in range(10):\n",
        "      if q == 9:\n",
        "        id_test.append(folder[-3:].replace('/', ''))\n",
        "      else:\n",
        "        id_train.append(folder[-3:].replace('/', ''))\n",
        "        # print(folder[-3:])\n",
        "  \n",
        "    # Iterates through all the images in folder and add in train_images\n",
        "    k = 0\n",
        "    for image in glob.glob(folder + '/*'):\n",
        "        read_image = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
        "        resized_image = cv2.resize(read_image, (shape[1], shape[0]))\n",
        "        if k == 9:\n",
        "          test_images[j] = np.array(resized_image)\n",
        "          test_images_dict[j] = resized_image\n",
        "          j = j + 1\n",
        "        else:\n",
        "          train_images[i] = np.array(resized_image)\n",
        "          i = i + 1\n",
        "        # print(train_images[i])\n",
        "        k = k + 1\n",
        "\n",
        "# Plots row*col images (20 in this case), first 20 in training set\n",
        "plot_images(train_images, id_train, 112,92, 2, 10)\n",
        "\n",
        "# print(id_train, id_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code section below plots the images in test set\n"
      ],
      "metadata": {
        "id": "vbmsQls_6di3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots row*col images (40 in this case, All in test set\n",
        "plot_images(test_images, id_test, 112, 92, 4, 10)"
      ],
      "metadata": {
        "id": "G96SkjqaD1gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Average Face\n",
        "The code section plots the mean face of the training set."
      ],
      "metadata": {
        "id": "LnjPj24k6kD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jblkl_6Ynveq"
      },
      "outputs": [],
      "source": [
        "# Convert the nxn image vectors inside train_images matrix to 1 x n^2 matrix and resize\n",
        "# Finally, F is of the order m x n^2 where m = number of images\n",
        "F = np.resize(train_images, (total_images, shape[0]*shape[1]))\n",
        "\n",
        "# The mean matrix is calculated by summing the elements of F and then dividing by total_images\n",
        "average_vector = np.sum(F, axis=0, dtype='float64')/total_images\n",
        "\n",
        "# Duplicate average vector into m x n^2 matrix to calculate differences\n",
        "average_matrix = np.tile(average_vector, (total_images, 1)) \n",
        "\n",
        "# Mean subtracted image matrix\n",
        "F_tilde = F - average_matrix\n",
        "\n",
        "# Plot the mean image\n",
        "plt.imshow(np.resize(average_vector, (shape[0],shape[1])), cmap='gray')\n",
        "plt.title('Average Face')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean Subtracted Image"
      ],
      "metadata": {
        "id": "kiordPue6xKC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_qPGdZxnver"
      },
      "outputs": [],
      "source": [
        "# F_tilde contains vectors of each mean subtracted image\n",
        "plot_images(F_tilde, id_train, 112,92, 2, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eigenfaces"
      ],
      "metadata": {
        "id": "-NOZivDp6165"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vd0eYWjnves"
      },
      "outputs": [],
      "source": [
        "# L is MxM matrix as mentioned in the paper and is used to find out eigenvectors\n",
        "L = (F_tilde.dot(F_tilde.T))/total_images\n",
        "print(\"L shape : \", L.shape)\n",
        "\n",
        "# Calculate eigenvalues and eigenvectors from L\n",
        "eigenvalues, eigenvectors = np.linalg.eig(L)\n",
        "\n",
        "# Sort the eigenvalues and eigenvectors in descending order to obtain highest\n",
        "# eigenvalue by using the indices\n",
        "idx = eigenvalues.argsort()[::-1]\n",
        "eigenvalues = eigenvalues[idx] \n",
        "eigenvectors = eigenvectors[:, idx]\n",
        "\n",
        "# Matrix multiplication by linear combinarion of each column of F_tilde\n",
        "# Resultant contains eigenvector of C in each column\n",
        "eigenvectors_C = F_tilde.T @ eigenvectors\n",
        "print(\"Eigenvectors shape : \", eigenvectors_C.shape)\n",
        "\n",
        "# Normalize eigenvectors to get eigenfaces\n",
        "eigenfaces = preprocessing.normalize(eigenvectors_C.T)\n",
        "print(\"Eigenfaces shape : \", eigenfaces.shape)\n",
        "\n",
        "# Plots first 20 eigenfaces\n",
        "eigenface_labels = [x for x in range(eigenfaces.shape[0])]\n",
        "plot_images(eigenfaces, eigenface_labels , 112,92, 2, 10) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean Subtracted Images of the Test Set"
      ],
      "metadata": {
        "id": "vlC2-b_r65pR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXiCILZanveu"
      },
      "outputs": [],
      "source": [
        "# Stores all the vectors that represent image with respect to the eigenfaces\n",
        "omega = dict()\n",
        "\n",
        "# Stores the subtracted mean of the testing images\n",
        "mean_subtracted_testing_dict = dict()\n",
        "\n",
        "# The number of chosen eigenfaces\n",
        "q = 350\n",
        "\n",
        "def omega_mst(test_image):\n",
        "  mean_subtracted_testing = np.reshape(test_image, (test_image.shape[0]*test_image.shape[1])) - average_vector\n",
        "  omega = eigenfaces[:q].dot(mean_subtracted_testing)\n",
        "  return (mean_subtracted_testing, omega)\n",
        "  \n",
        "# Store the values\n",
        "for j in test_images_dict:\n",
        "  mean_subtracted_testing_dict[j] = omega_mst(test_images_dict[j])[0]\n",
        "  omega[j] = omega_mst(test_images_dict[j])[1]\n",
        "  # print(omega.shape)\n",
        "\n",
        "# fig = plt.figure(figsize=(10, 7))\n",
        "  \n",
        "# # setting values to rows and column variables\n",
        "# rows = 3\n",
        "# columns = 3\n",
        "\n",
        "# # Plot the mean subtracted test image\n",
        "for j in test_images_dict:\n",
        "  plt.imshow(np.reshape(mean_subtracted_testing_dict[j], (112,92)), cmap='gray')\n",
        "  plt.title(\"Mean Subtracted Test Image\")\n",
        "  plt.show()\n",
        "\n",
        "  # fig.add_subplot(rows, columns, j+1)\n",
        "\n",
        "  # # showing image\n",
        "  # plt.imshow(np.reshape(mean_subtracted_testing_dict[j], (112,92)), cmap='gray')\n",
        "  # plt.axis('off')\n",
        "  # plt.title(str(j))\n",
        "\n",
        "def mst_face(mst):\n",
        "  plt.imshow(np.reshape(mst, (112,92)), cmap='gray')\n",
        "  plt.title(\"Mean Subtracted Test Image\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reconstructed Images of the Test Set"
      ],
      "metadata": {
        "id": "q_qAXpsy6_1b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67TO5fYznvev"
      },
      "outputs": [],
      "source": [
        "# To plot the reconstructed face image\n",
        "def face_reconstruct(omega_val):\n",
        "  # Image reconstruction depends on q eigenfaces\n",
        "  reconstructed = eigenfaces[:q].T.dot(omega_val) \n",
        "  # print(reconstructed.shape)\n",
        "\n",
        "  plt.imshow(np.reshape(reconstructed, (shape[0],shape[1])), cmap='gray')\n",
        "  plt.title(\"Reconstructed image - \"+str(q)+\" eigenfaces\")\n",
        "  plt.show()\n",
        "\n",
        "# Plot the reconstructed face image\n",
        "for i in omega:\n",
        "  face_reconstruct(omega[i])\n",
        "\n",
        "# fig = plt.figure(figsize=(10, 7))\n",
        "  \n",
        "# # setting values to rows and column variables\n",
        "# rows = 3\n",
        "# columns = 3\n",
        "\n",
        "# # Plot the mean subtracted test image\n",
        "# for j in range(9):\n",
        "#   # plt.imshow(np.reshape(mean_subtracted_testing_dict[j], (112,92)), cmap='gray')\n",
        "#   # plt.title(\"Mean Subtracted Test Image\")\n",
        "#   # plt.show()\n",
        "\n",
        "#   fig.add_subplot(rows, columns, j+1)\n",
        "\n",
        "#   # showing image\n",
        "#   reconstructed = eigenfaces[:q].T.dot(omega[j]) \n",
        "#   # print(reconstructed.shape)\n",
        "#   plt.imshow(np.reshape(reconstructed, (shape[0],shape[1])), cmap='gray')\n",
        "#   plt.axis('off')\n",
        "#   plt.title(str(j))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for face detection\n",
        "Detects the face using omega and mean subtracted testing values of a particular image. The correct value of alpha_1 is obtained by trial and error. It is 3000 in this case."
      ],
      "metadata": {
        "id": "Nrc-Co2N7Kdh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjTF0xT6nvew"
      },
      "outputs": [],
      "source": [
        "def face_detect(omega_val, mean_subtracted_testing_val):\n",
        "  # Threshold for face detection\n",
        "  alpha_1 = 3000\n",
        "\n",
        "  # nxn vector of the test face image represented as the linear combination \n",
        "  # of the chosen eigenfaces\n",
        "  projected_new_img_vector = eigenfaces[:q].T @ omega_val \n",
        "\n",
        "  # Beta is the distance between the original face image vector and \n",
        "  # the projected vector. Compared with the threshold.\n",
        "  diff = mean_subtracted_testing_val - projected_new_img_vector \n",
        "  beta = math.sqrt(diff.dot(diff)) \n",
        "\n",
        "  if beta < alpha_1:\n",
        "      print(\"Face detected! \", beta)\n",
        "  else:\n",
        "      print(\"No face detected! \", beta)\n",
        "\n",
        "\n",
        "for i in omega:\n",
        "  face_detect(omega[i], mean_subtracted_testing_dict[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Face Recognition\n",
        "Recognizes faces using the omega value of a particular image. The correct value of alpha_2 is obtained by trial and error. It is 3200 in this case. It returns 4 things.Firstly, it returns all the matching indexes whose value is lower than the threshold. Then it selects the smallest of those values and return the index and the correponsding label/id."
      ],
      "metadata": {
        "id": "LWS8Gd687Wt9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJaMmeh1nvew"
      },
      "outputs": [],
      "source": [
        "def face_recognize(omega_val):\n",
        "  # Threshold for face recognition\n",
        "  alpha_2 = 3200\n",
        "\n",
        "   # Keep track of the smallest value for face recognition\n",
        "  smallest_value = None\n",
        "\n",
        "  # The face image/class that produces the smallest value\n",
        "  index = None \n",
        "\n",
        "  # Indexes of matching images to the given test image \n",
        "  matching_indexes = list()\n",
        "\n",
        "  # Calculate pattern vector and distance to each know class (face image in the\n",
        "  # traingin dataset)\n",
        "  for k in range(total_images):\n",
        "      omega_k = eigenfaces[:q].dot(F_tilde[k])  \n",
        "      diff = omega_val - omega_k\n",
        "      epsilon_k = math.sqrt(diff.dot(diff))\n",
        "      if smallest_value == None:\n",
        "          smallest_value = epsilon_k\n",
        "          index = k\n",
        "      if smallest_value > epsilon_k:\n",
        "          smallest_value = epsilon_k\n",
        "          index = k\n",
        "          matching_indexes.append(k)\n",
        "\n",
        "  if smallest_value < alpha_2:\n",
        "      # index += 1\n",
        "      # print(smallest_value, id_train[index])\n",
        "      return (smallest_value, id_train[index], index, matching_indexes)\n",
        "  else:\n",
        "      # print(smallest_value, \"Unknown Face!\")\n",
        "      return (smallest_value, \"Unknown Face!\", index, matching_indexes)\n",
        "\n",
        "print(\"Matching indexes: \")\n",
        "for i in omega:\n",
        "  res = face_recognize(omega[i])\n",
        "  if res[1] == \"Unknown Face\":\n",
        "    print(str(i) + \". \" + \"Above Threshold   Smallest index = \" + str(res[2]))\n",
        "    print(\"Matching indexes = \" + str(res[3]))\n",
        "  else:\n",
        "    print(str(i) + \". \" + \"Below Threshold   Smallest index = \" + str(res[2]))\n",
        "    print(\"Matching indexes = \" + str(res[3]))\n",
        "\n",
        "print(\" \")\n",
        "print(\"Result: \")\n",
        "accuracy = 0\n",
        "for i in omega:\n",
        "  res = face_recognize(omega[i])\n",
        "  if res[1] == \"Unknown Face\":\n",
        "    print(str(i) + \". \" + \"Actual-Id: \" + str(id_test[i]) + \"   Result: Unkown Face!   smallest_value: \" + str(res[0]))\n",
        "  elif res[1] != id_test[i]:\n",
        "    print(str(i) + \". \" + \"Actual-Id: \" + str(id_test[i]) + \"   Result: \" + str(res[1]) + \"   smallest_value: \" + str(res[0]))\n",
        "  else:\n",
        "    print(str(i) + \". \" + \"Actual-Id: \" + str(id_test[i]) + \"   Result: \" + str(res[1]) + \"   smallest_value: \" + str(res[0]))\n",
        "    accuracy += 1\n",
        "  \n",
        "percent_accuracy = (accuracy / 40) * 100\n",
        "print(\"Correctly recognized: \" + str(accuracy) + \" images out of 40 images.\")\n",
        "print(\"Accuracy: \" + str(percent_accuracy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Test Set\n",
        "After testing my algorithm on the test above, I tried using a random test set with very limited images, i.e., only 10 as of now to test the face detection and recogniton. These 10 images are not from any internationally recognized standard datasets. These are just some random images that I found on internet. The algorithm performs satifactorily in this case too. \n",
        "\n",
        "You can also see the mean subtracted images and the reconstructed images by running the code section present below."
      ],
      "metadata": {
        "id": "pCgmH7Ic72rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 11):\n",
        "  test_img = cv2.imread('/content/sample_data/test'+ str(i)+'.jpg', cv2.IMREAD_GRAYSCALE) #testing image\n",
        "  test_img = cv2.resize(test_img, (shape[1],shape[0])) #resize the testing image. cv2 resize by width and height.\n",
        "  mean_subtracted_testing, omega = omega_mst(test_img)[0], omega_mst(test_img)[1]\n",
        "  mst_face(mean_subtracted_testing)\n",
        "  face_reconstruct(omega)\n",
        "  face_detect(omega, mean_subtracted_testing)\n",
        "  res = face_recognize(omega)\n",
        "  print(res[0], res[1], res[2], res[3])"
      ],
      "metadata": {
        "id": "pGJye_KWb7um"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}